library(tidytext)
library(tidyverse)
library(janeaustenr)
library(tm)    
```

Using tidy data principles can make many text mining tasks easier, more effective, and consistent with tools already in wide use. Much of the infrastructure needed for text mining with tidy data frames already exists in packages like **dplyr**, **broom**, **tidyr** and **ggplot2**. In this package, we provide functions and supporting data sets to allow conversion of text to and from tidy formats, and to switch seamlessly between tidy tools and existing text mining packages. 

## Tidy text mining example: the *unnest_tokens* function

The novels of Jane Austen can be so tidy! Let's use the text of Jane Austen's 6 completed, published novels from the **janeaustenr** package, and bring them into a tidy format. **janeaustenr** provides them as a one-row-per-line format:

```{r}
original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(line = row_number()) %>%
  ungroup()

original_books
```

To work with this as a tidy dataset, we need to restructure it as *one-token-per-row* format. The *unnest_tokens* function is a way to convert a dataframe with a text column to be one-token-per-row:

```{r}
tidy_books <- original_books %>%
  unnest_tokens(word, text)

tidy_books
```

This function uses the tokenizers package to separate each line into words. The default tokenizing is for *words*, but other options include *characters*, *n-grams*, *sentences*, *lines*, *paragraphs*, or separation around a regex pattern.

Now that the data is in *one-word-per-row* format, we can manipulate it with tidy tools like dplyr. We can remove stop words (kept in the tidytext dataset stop_words) with an anti_join.

```{r}
data("stop_words")
tidy_books <- tidy_books %>%
  anti_join(stop_words, by="word")
```

We can also use *count* to find the most common words in all the books as a whole.

```{r}
tidy_books %>%
  count(word, sort = TRUE) 
```

**Sentiment analysis** can be done as an inner join. Three sentiment lexicons are available via the *get_sentiments()* function. Let's examine how sentiment changes during each novel. Let's find a sentiment score for each word using the Bing lexicon, then count the number of positive and negative words in defined sections of each novel.

```{r}
get_sentiments("bing")

janeaustensentiment <- tidy_books %>%
  inner_join(get_sentiments("bing"), by = "word") %>% 
  count(book, index = line %/% 100, sentiment) %>%  # count the sentiment words group by book and every                                                            100 lines (words)
  spread(sentiment, n, fill = 0) %>% 
  mutate(sentiment = positive - negative)


janeaustensentiment

```


Now we can plot these sentiment scores across the plot trajectory of each novel.

```{r}
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
  geom_bar(stat = "identity", show.legend = FALSE)  +     # or geom_col()
  facet_wrap(~book, ncol = 2, scales = "free_x")
```
